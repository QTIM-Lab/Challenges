Participants’ MAR images will be evaluated relative to the ground truth images unknown to them, based on ~7 metrics per case, including structural similarity, root-mean-square-error (RMSE) inside a region of interest, spatial resolution, noise, lesion detectability, feature dimension accuracy, and residual streak amplitude. The final score will be defined as a weighted average of the 7 image quality metrics across all (preliminary or final) scoring images:
<img src="https://www.aapm.org/GrandChallenge/CT-MAR/images/Figure5.png" width=370px height=133px>
<img src="https://www.aapm.org/GrandChallenge/CT-MAR/images/equation.png" width=180px height=50px>

where c is the case index, m is the metric index, C is the total number of cases, and Equation. The weights will be refined in discussion between CT physicists and clinical experts to be the most representative for overall performance. The computational complexity of participant’s algorithm will be documented but will not be included in the overall score. Representative images and some sample metrics are shown in Figure 5. A ground truth image (without metal), a corrupted image (with metal), and a MAR-corrected image are shown along with sample ROIs where the final score will be computed. The noise and RMSE numbers are shown as illustration in this example.